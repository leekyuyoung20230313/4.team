{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-21T13:00:30.938122Z","iopub.execute_input":"2023-08-21T13:00:30.938552Z","iopub.status.idle":"2023-08-21T13:00:30.968558Z","shell.execute_reply.started":"2023-08-21T13:00:30.938524Z","shell.execute_reply":"2023-08-21T13:00:30.967520Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cafa-5-protein-function-prediction/sample_submission.tsv\n/kaggle/input/cafa-5-protein-function-prediction/IA.txt\n/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\n/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset-taxon-list.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\n/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\n/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo\n/kaggle/input/t5embeds/train_ids.npy\n/kaggle/input/t5embeds/test_embeds.npy\n/kaggle/input/t5embeds/train_embeds.npy\n/kaggle/input/t5embeds/test_ids.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Required for progressbar widget\nimport progressbar","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:00:30.970427Z","iopub.execute_input":"2023-08-21T13:00:30.971272Z","iopub.status.idle":"2023-08-21T13:00:47.332887Z","shell.execute_reply.started":"2023-08-21T13:00:30.971245Z","shell.execute_reply":"2023-08-21T13:00:47.331727Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_terms = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\",sep=\"\\t\")\nprint(train_terms.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:00:47.335415Z","iopub.execute_input":"2023-08-21T13:00:47.336447Z","iopub.status.idle":"2023-08-21T13:00:50.969015Z","shell.execute_reply.started":"2023-08-21T13:00:47.336407Z","shell.execute_reply":"2023-08-21T13:00:50.968091Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(5363863, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_protein_ids = np.load('/kaggle/input/t5embeds/train_ids.npy')\nprint(train_protein_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:00:50.970319Z","iopub.execute_input":"2023-08-21T13:00:50.970679Z","iopub.status.idle":"2023-08-21T13:00:51.029419Z","shell.execute_reply.started":"2023-08-21T13:00:50.970645Z","shell.execute_reply":"2023-08-21T13:00:51.028372Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(142246,)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_embeddings = np.load('/kaggle/input/t5embeds/train_embeds.npy')\n\n# Now lets convert embeddings numpy array(train_embeddings) into pandas dataframe.\ncolumn_num = train_embeddings.shape[1]\ntrain_df = pd.DataFrame(train_embeddings, columns = [\"Column_\" + str(i) for i in range(1, column_num+1)])\nprint(train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:00:51.032150Z","iopub.execute_input":"2023-08-21T13:00:51.032601Z","iopub.status.idle":"2023-08-21T13:01:02.547959Z","shell.execute_reply.started":"2023-08-21T13:00:51.032568Z","shell.execute_reply":"2023-08-21T13:01:02.546875Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(142246, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the limit for label\nnum_of_labels = 1200\n\n# Take value counts in descending order and fetch first 1500 `GO term ID` as labels\nlabels = train_terms['term'].value_counts().index[:num_of_labels].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:01:02.549489Z","iopub.execute_input":"2023-08-21T13:01:02.549847Z","iopub.status.idle":"2023-08-21T13:01:03.434189Z","shell.execute_reply.started":"2023-08-21T13:01:02.549813Z","shell.execute_reply":"2023-08-21T13:01:03.433148Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Fetch the train_terms data for the relevant labels only\ntrain_terms_updated = train_terms.loc[train_terms['term'].isin(labels)]","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:01:03.435970Z","iopub.execute_input":"2023-08-21T13:01:03.436538Z","iopub.status.idle":"2023-08-21T13:01:04.095070Z","shell.execute_reply.started":"2023-08-21T13:01:03.436502Z","shell.execute_reply":"2023-08-21T13:01:04.093095Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Setup progressbar settings.\n# This is strictly for aesthetic.\nbar = progressbar.ProgressBar(maxval=num_of_labels, \\\n    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n\n# Create an empty dataframe of required size for storing the labels,\n# i.e, train_size x num_of_labels (142246 x 1500)\ntrain_size = train_protein_ids.shape[0] # len(X)\ntrain_labels = np.zeros((train_size ,num_of_labels))\n\n# Convert from numpy to pandas series for better handling\nseries_train_protein_ids = pd.Series(train_protein_ids)\n\n# Loop through each label\nfor i in range(num_of_labels):\n    # For each label, fetch the corresponding train_terms data\n    n_train_terms = train_terms_updated[train_terms_updated['term'] ==  labels[i]]\n    \n    # Fetch all the unique EntryId aka proteins related to the current label(GO term ID)\n    label_related_proteins = n_train_terms['EntryID'].unique()\n    \n    # In the series_train_protein_ids pandas series, if a protein is related\n    # to the current label, then mark it as 1, else 0.\n    # Replace the ith column of train_Y with with that pandas series.\n    train_labels[:,i] =  series_train_protein_ids.isin(label_related_proteins).astype(float)\n    \n    # Progress bar percentage increase\n    bar.update(i+1)\n\n# Notify the end of progress bar \nbar.finish()\n\n# Convert train_Y numpy into pandas dataframe\nlabels_df = pd.DataFrame(data = train_labels, columns = labels)\nprint(labels_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:01:04.096800Z","iopub.execute_input":"2023-08-21T13:01:04.097893Z","iopub.status.idle":"2023-08-21T13:15:09.594901Z","shell.execute_reply.started":"2023-08-21T13:01:04.097855Z","shell.execute_reply":"2023-08-21T13:15:09.593805Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"[========================================================================] 100%\n","output_type":"stream"},{"name":"stdout","text":"(142246, 1200)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LeakyReLU\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n\n# 모델 정의\nINPUT_SHAPE = [train_df.shape[1]]\nnum_of_labels = labels_df.shape[1]\nBATCH_SIZE = 512\n\nmodel = Sequential([\n    BatchNormalization(input_shape=INPUT_SHAPE),\n    Dense(units=1024, kernel_initializer='he_normal'),  # 더 깊은 층 추가\n    LeakyReLU(alpha=0.1),  # ELU 활성화 함수 추가\n    Dropout(0.5),  # 드롭아웃 확률을 높임\n    Dense(units=512, kernel_initializer='he_normal'),\n    LeakyReLU(alpha=0.1),  # ELU 활성화 함수 추가\n    Dropout(0.5),  # 드롭아웃 확률을 높임\n    Dense(units=256, kernel_initializer='he_normal'),\n    LeakyReLU(alpha=0.1),  # ELU 활성화 함수 추가\n    Dropout(0.4),  # 드롭아웃 확률을 높임\n    Dense(units=num_of_labels, activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.01),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy', AUC()]\n)\n\n# 학습률 스케줄링 및 조절\ndef lr_schedule(epoch, lr):\n    if epoch < 50:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\nlr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n\n# 얼리 스토핑 추가\nearly_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n\n# 모델 훈련\nhistory = model.fit(\n    train_df, labels_df,\n    batch_size=BATCH_SIZE,\n    epochs=200,\n    callbacks=[lr_scheduler, lr_reducer, early_stopping]\n)\n\n# 모델 저장\nmodel.save('MLP_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:15:09.596346Z","iopub.execute_input":"2023-08-21T13:15:09.596800Z","iopub.status.idle":"2023-08-21T13:25:43.846408Z","shell.execute_reply.started":"2023-08-21T13:15:09.596753Z","shell.execute_reply":"2023-08-21T13:25:43.845346Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/200\n278/278 [==============================] - 12s 11ms/step - loss: 0.1013 - binary_accuracy: 0.9727 - auc: 0.8371 - lr: 0.0100\nEpoch 2/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0828 - binary_accuracy: 0.9762 - auc: 0.8811 - lr: 0.0100\nEpoch 3/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0844 - binary_accuracy: 0.9761 - auc: 0.8746 - lr: 0.0100\nEpoch 4/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0868 - binary_accuracy: 0.9757 - auc: 0.8754 - lr: 0.0100\nEpoch 5/200\n278/278 [==============================] - 3s 11ms/step - loss: 22.1077 - binary_accuracy: 0.9525 - auc: 0.5824 - lr: 0.0100\nEpoch 6/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.8624 - binary_accuracy: 0.9585 - auc: 0.6317 - lr: 0.0100\nEpoch 7/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.4972 - binary_accuracy: 0.9598 - auc: 0.6761 - lr: 0.0100\nEpoch 8/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.3961 - binary_accuracy: 0.9623 - auc: 0.6974 - lr: 0.0100\nEpoch 9/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.2496 - binary_accuracy: 0.9653 - auc: 0.7242 - lr: 0.0100\nEpoch 10/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.1888 - binary_accuracy: 0.9682 - auc: 0.7425 - lr: 0.0100\nEpoch 11/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.1587 - binary_accuracy: 0.9703 - auc: 0.7545 - lr: 0.0100\nEpoch 12/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.1390 - binary_accuracy: 0.9719 - auc: 0.7650 - lr: 0.0100\nEpoch 13/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.1271 - binary_accuracy: 0.9730 - auc: 0.7733 - lr: 0.0100\nEpoch 14/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.1205 - binary_accuracy: 0.9736 - auc: 0.7785 - lr: 0.0100\nEpoch 15/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.1126 - binary_accuracy: 0.9743 - auc: 0.7864 - lr: 0.0100\nEpoch 16/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.1081 - binary_accuracy: 0.9747 - auc: 0.7925 - lr: 0.0100\nEpoch 17/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.1028 - binary_accuracy: 0.9751 - auc: 0.8013 - lr: 0.0100\nEpoch 18/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0995 - binary_accuracy: 0.9753 - auc: 0.8088 - lr: 0.0100\nEpoch 19/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0977 - binary_accuracy: 0.9754 - auc: 0.8140 - lr: 0.0100\nEpoch 20/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0972 - binary_accuracy: 0.9753 - auc: 0.8175 - lr: 0.0100\nEpoch 21/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0941 - binary_accuracy: 0.9755 - auc: 0.8264 - lr: 0.0100\nEpoch 22/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0925 - binary_accuracy: 0.9756 - auc: 0.8328 - lr: 0.0100\nEpoch 23/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0930 - binary_accuracy: 0.9755 - auc: 0.8333 - lr: 0.0100\nEpoch 24/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0905 - binary_accuracy: 0.9757 - auc: 0.8423 - lr: 0.0100\nEpoch 25/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0893 - binary_accuracy: 0.9757 - auc: 0.8482 - lr: 0.0100\nEpoch 26/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0881 - binary_accuracy: 0.9758 - auc: 0.8545 - lr: 0.0100\nEpoch 27/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0869 - binary_accuracy: 0.9759 - auc: 0.8601 - lr: 0.0100\nEpoch 28/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0858 - binary_accuracy: 0.9760 - auc: 0.8656 - lr: 0.0100\nEpoch 29/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0860 - binary_accuracy: 0.9759 - auc: 0.8646 - lr: 0.0100\nEpoch 30/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0850 - binary_accuracy: 0.9760 - auc: 0.8696 - lr: 0.0100\nEpoch 31/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0841 - binary_accuracy: 0.9761 - auc: 0.8741 - lr: 0.0100\nEpoch 32/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0833 - binary_accuracy: 0.9761 - auc: 0.8778 - lr: 0.0100\nEpoch 33/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0827 - binary_accuracy: 0.9762 - auc: 0.8808 - lr: 0.0100\nEpoch 34/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0827 - binary_accuracy: 0.9762 - auc: 0.8808 - lr: 0.0100\nEpoch 35/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0820 - binary_accuracy: 0.9762 - auc: 0.8842 - lr: 0.0100\nEpoch 36/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0816 - binary_accuracy: 0.9762 - auc: 0.8860 - lr: 0.0100\nEpoch 37/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0817 - binary_accuracy: 0.9762 - auc: 0.8858 - lr: 0.0100\nEpoch 38/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0810 - binary_accuracy: 0.9763 - auc: 0.8891 - lr: 0.0100\nEpoch 39/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0808 - binary_accuracy: 0.9763 - auc: 0.8898 - lr: 0.0100\nEpoch 40/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0811 - binary_accuracy: 0.9763 - auc: 0.8885 - lr: 0.0100\nEpoch 41/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0805 - binary_accuracy: 0.9763 - auc: 0.8913 - lr: 0.0100\nEpoch 42/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0803 - binary_accuracy: 0.9763 - auc: 0.8918 - lr: 0.0100\nEpoch 43/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0800 - binary_accuracy: 0.9763 - auc: 0.8932 - lr: 0.0100\nEpoch 44/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0799 - binary_accuracy: 0.9763 - auc: 0.8938 - lr: 0.0100\nEpoch 45/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0799 - binary_accuracy: 0.9763 - auc: 0.8940 - lr: 0.0100\nEpoch 46/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0796 - binary_accuracy: 0.9764 - auc: 0.8955 - lr: 0.0100\nEpoch 47/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0794 - binary_accuracy: 0.9764 - auc: 0.8963 - lr: 0.0100\nEpoch 48/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0790 - binary_accuracy: 0.9764 - auc: 0.8976 - lr: 0.0100\nEpoch 49/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0786 - binary_accuracy: 0.9765 - auc: 0.8996 - lr: 0.0100\nEpoch 50/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0782 - binary_accuracy: 0.9765 - auc: 0.9011 - lr: 0.0100\nEpoch 51/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0785 - binary_accuracy: 0.9765 - auc: 0.8999 - lr: 0.0090\nEpoch 52/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0772 - binary_accuracy: 0.9766 - auc: 0.9051 - lr: 0.0082\nEpoch 53/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0768 - binary_accuracy: 0.9766 - auc: 0.9069 - lr: 0.0074\nEpoch 54/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0762 - binary_accuracy: 0.9767 - auc: 0.9090 - lr: 0.0067\nEpoch 55/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0762 - binary_accuracy: 0.9767 - auc: 0.9088 - lr: 0.0061\nEpoch 56/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0754 - binary_accuracy: 0.9768 - auc: 0.9118 - lr: 0.0055\nEpoch 57/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0750 - binary_accuracy: 0.9768 - auc: 0.9129 - lr: 0.0050\nEpoch 58/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0747 - binary_accuracy: 0.9769 - auc: 0.9144 - lr: 0.0045\nEpoch 59/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0743 - binary_accuracy: 0.9769 - auc: 0.9154 - lr: 0.0041\nEpoch 60/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0740 - binary_accuracy: 0.9770 - auc: 0.9167 - lr: 0.0037\nEpoch 61/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0735 - binary_accuracy: 0.9770 - auc: 0.9182 - lr: 0.0033\nEpoch 62/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0731 - binary_accuracy: 0.9771 - auc: 0.9195 - lr: 0.0030\nEpoch 63/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0727 - binary_accuracy: 0.9771 - auc: 0.9207 - lr: 0.0027\nEpoch 64/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0723 - binary_accuracy: 0.9772 - auc: 0.9220 - lr: 0.0025\nEpoch 65/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0720 - binary_accuracy: 0.9773 - auc: 0.9228 - lr: 0.0022\nEpoch 66/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0716 - binary_accuracy: 0.9773 - auc: 0.9242 - lr: 0.0020\nEpoch 67/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0714 - binary_accuracy: 0.9774 - auc: 0.9248 - lr: 0.0018\nEpoch 68/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0709 - binary_accuracy: 0.9775 - auc: 0.9260 - lr: 0.0017\nEpoch 69/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0707 - binary_accuracy: 0.9775 - auc: 0.9266 - lr: 0.0015\nEpoch 70/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0704 - binary_accuracy: 0.9775 - auc: 0.9277 - lr: 0.0014\nEpoch 71/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0701 - binary_accuracy: 0.9776 - auc: 0.9283 - lr: 0.0012\nEpoch 72/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0699 - binary_accuracy: 0.9776 - auc: 0.9289 - lr: 0.0011\nEpoch 73/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0696 - binary_accuracy: 0.9776 - auc: 0.9298 - lr: 0.0010\nEpoch 74/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0694 - binary_accuracy: 0.9777 - auc: 0.9304 - lr: 9.0718e-04\nEpoch 75/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0692 - binary_accuracy: 0.9777 - auc: 0.9309 - lr: 8.2085e-04\nEpoch 76/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0690 - binary_accuracy: 0.9778 - auc: 0.9316 - lr: 7.4273e-04\nEpoch 77/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0688 - binary_accuracy: 0.9778 - auc: 0.9319 - lr: 6.7205e-04\nEpoch 78/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0686 - binary_accuracy: 0.9778 - auc: 0.9325 - lr: 6.0810e-04\nEpoch 79/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0685 - binary_accuracy: 0.9779 - auc: 0.9329 - lr: 5.5023e-04\nEpoch 80/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0683 - binary_accuracy: 0.9779 - auc: 0.9332 - lr: 4.9787e-04\nEpoch 81/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0682 - binary_accuracy: 0.9779 - auc: 0.9335 - lr: 4.5049e-04\nEpoch 82/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0681 - binary_accuracy: 0.9779 - auc: 0.9339 - lr: 4.0762e-04\nEpoch 83/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0680 - binary_accuracy: 0.9779 - auc: 0.9340 - lr: 3.6883e-04\nEpoch 84/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0679 - binary_accuracy: 0.9780 - auc: 0.9344 - lr: 3.3373e-04\nEpoch 85/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0678 - binary_accuracy: 0.9780 - auc: 0.9347 - lr: 3.0197e-04\nEpoch 86/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0677 - binary_accuracy: 0.9780 - auc: 0.9349 - lr: 2.7324e-04\nEpoch 87/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0676 - binary_accuracy: 0.9780 - auc: 0.9350 - lr: 2.4723e-04\nEpoch 88/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0676 - binary_accuracy: 0.9780 - auc: 0.9353 - lr: 2.2371e-04\nEpoch 89/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0675 - binary_accuracy: 0.9781 - auc: 0.9354 - lr: 2.0242e-04\nEpoch 90/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0674 - binary_accuracy: 0.9781 - auc: 0.9356 - lr: 1.8316e-04\nEpoch 91/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0674 - binary_accuracy: 0.9781 - auc: 0.9355 - lr: 1.6573e-04\nEpoch 92/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0673 - binary_accuracy: 0.9781 - auc: 0.9359 - lr: 1.4996e-04\nEpoch 93/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0672 - binary_accuracy: 0.9781 - auc: 0.9360 - lr: 1.3569e-04\nEpoch 94/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0673 - binary_accuracy: 0.9781 - auc: 0.9359 - lr: 1.2277e-04\nEpoch 95/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0672 - binary_accuracy: 0.9781 - auc: 0.9362 - lr: 1.1109e-04\nEpoch 96/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0671 - binary_accuracy: 0.9781 - auc: 0.9363 - lr: 1.0052e-04\nEpoch 97/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0672 - binary_accuracy: 0.9781 - auc: 0.9362 - lr: 9.0953e-05\nEpoch 98/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0671 - binary_accuracy: 0.9781 - auc: 0.9364 - lr: 8.2297e-05\nEpoch 99/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0671 - binary_accuracy: 0.9781 - auc: 0.9364 - lr: 7.4466e-05\nEpoch 100/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0671 - binary_accuracy: 0.9781 - auc: 0.9363 - lr: 6.7379e-05\nEpoch 101/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0670 - binary_accuracy: 0.9782 - auc: 0.9366 - lr: 6.0967e-05\nEpoch 102/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0670 - binary_accuracy: 0.9781 - auc: 0.9364 - lr: 5.5166e-05\nEpoch 103/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0670 - binary_accuracy: 0.9781 - auc: 0.9366 - lr: 4.9916e-05\nEpoch 104/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0670 - binary_accuracy: 0.9781 - auc: 0.9368 - lr: 4.5166e-05\nEpoch 105/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 4.0868e-05\nEpoch 106/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0670 - binary_accuracy: 0.9781 - auc: 0.9367 - lr: 3.6979e-05\nEpoch 107/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 3.3460e-05\nEpoch 108/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 3.0275e-05\nEpoch 109/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0670 - binary_accuracy: 0.9782 - auc: 0.9367 - lr: 2.7394e-05\nEpoch 110/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 2.4787e-05\nEpoch 111/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 2.2429e-05\nEpoch 112/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 2.0294e-05\nEpoch 113/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9781 - auc: 0.9368 - lr: 1.8363e-05\nEpoch 114/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0669 - binary_accuracy: 0.9781 - auc: 0.9370 - lr: 1.6616e-05\nEpoch 115/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 1.5034e-05\nEpoch 116/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 1.3604e-05\nEpoch 117/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 1.2309e-05\nEpoch 118/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.1138e-05\nEpoch 119/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.0078e-05\nEpoch 120/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 9.1188e-06\nEpoch 121/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 8.2510e-06\nEpoch 122/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 7.4658e-06\nEpoch 123/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 6.7554e-06\nEpoch 124/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 6.1125e-06\nEpoch 125/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 5.5308e-06\nEpoch 126/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 5.0045e-06\nEpoch 127/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 4.5283e-06\nEpoch 128/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 4.0973e-06\nEpoch 129/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 3.7074e-06\nEpoch 130/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 3.3546e-06\nEpoch 131/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 3.0354e-06\nEpoch 132/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 2.7465e-06\nEpoch 133/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 2.4852e-06\nEpoch 134/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 2.2487e-06\nEpoch 135/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 2.0347e-06\nEpoch 136/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 1.8410e-06\nEpoch 137/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 1.6659e-06\nEpoch 138/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 1.5073e-06\nEpoch 139/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9373 - lr: 1.3639e-06\nEpoch 140/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 1.2341e-06\nEpoch 141/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 1.1167e-06\nEpoch 142/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.0104e-06\nEpoch 143/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 9.1424e-07\nEpoch 144/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 8.2724e-07\nEpoch 145/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 7.4851e-07\nEpoch 146/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 6.7728e-07\nEpoch 147/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 6.1283e-07\nEpoch 148/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 5.5451e-07\nEpoch 149/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 5.0174e-07\nEpoch 150/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 4.5400e-07\nEpoch 151/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0667 - binary_accuracy: 0.9782 - auc: 0.9373 - lr: 4.1079e-07\nEpoch 152/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 3.7170e-07\nEpoch 153/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 3.3633e-07\nEpoch 154/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 3.0432e-07\nEpoch 155/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 2.7536e-07\nEpoch 156/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 2.4916e-07\nEpoch 157/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9373 - lr: 2.2545e-07\nEpoch 158/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 2.0399e-07\nEpoch 159/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.8458e-07\nEpoch 160/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 1.6702e-07\nEpoch 161/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9781 - auc: 0.9371 - lr: 1.5112e-07\nEpoch 162/200\n278/278 [==============================] - 3s 11ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.3674e-07\nEpoch 163/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 1.2373e-07\nEpoch 164/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 1.1195e-07\nEpoch 165/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.0130e-07\nEpoch 166/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 9.1660e-08\nEpoch 167/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9367 - lr: 8.2938e-08\nEpoch 168/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 7.5045e-08\nEpoch 169/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 6.7904e-08\nEpoch 170/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 6.1442e-08\nEpoch 171/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9781 - auc: 0.9370 - lr: 5.5595e-08\nEpoch 172/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 5.0304e-08\nEpoch 173/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 4.5517e-08\nEpoch 174/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 4.1186e-08\nEpoch 175/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 3.7266e-08\nEpoch 176/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 3.3720e-08\nEpoch 177/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 3.0511e-08\nEpoch 178/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0669 - binary_accuracy: 0.9781 - auc: 0.9370 - lr: 2.7608e-08\nEpoch 179/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 2.4980e-08\nEpoch 180/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 2.2603e-08\nEpoch 181/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 2.0452e-08\nEpoch 182/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.8506e-08\nEpoch 183/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.6745e-08\nEpoch 184/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.5151e-08\nEpoch 185/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.3709e-08\nEpoch 186/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 1.2405e-08\nEpoch 187/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 1.1224e-08\nEpoch 188/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 1.0156e-08\nEpoch 189/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 9.1897e-09\nEpoch 190/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9368 - lr: 8.3152e-09\nEpoch 191/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9781 - auc: 0.9370 - lr: 7.5239e-09\nEpoch 192/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 6.8079e-09\nEpoch 193/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 6.1601e-09\nEpoch 194/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 5.5739e-09\nEpoch 195/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 5.0434e-09\nEpoch 196/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9371 - lr: 4.5635e-09\nEpoch 197/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9370 - lr: 4.1292e-09\nEpoch 198/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0669 - binary_accuracy: 0.9782 - auc: 0.9369 - lr: 3.7363e-09\nEpoch 199/200\n278/278 [==============================] - 3s 10ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 3.3807e-09\nEpoch 200/200\n278/278 [==============================] - 3s 12ms/step - loss: 0.0668 - binary_accuracy: 0.9782 - auc: 0.9372 - lr: 3.0590e-09\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}